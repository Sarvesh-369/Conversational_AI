{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Things to find:<br />\n",
        "1)Length of the document(i.e No.of terms after tokenization)(find average also)<br />\n",
        "2)Length of each section (i.e No.of terms after tokenization)(find average also)<br />\n",
        "3)How many links per document(find average also)<br />\n",
        "4)links received per section(find average also)<br />\n",
        "5)number of images for entire document)<br />\n",
        "6)number of images per section<br />\n",
        "7)number of duplicate links<br />\n",
        "8)Length of the document post pre processing\n"
      ],
      "metadata": {
        "id": "Ii5IyoqSHgtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)Named Entity recognition<br />\n",
        "2)POS tagger<br />\n",
        "3)Semantic tagger"
      ],
      "metadata": {
        "id": "uzI7Szhsb3TX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juitNmLFL0JV",
        "outputId": "8800c672-55ef-4876-9208-02613f70ffb6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Function to extract the length of a document\n",
        "def get_document_length(text):\n",
        "    words = word_tokenize(text)\n",
        "    return len(words)\n",
        "\n",
        "# Function to calculate the average value\n",
        "def calculate_average(values):\n",
        "    if len(values) > 0:\n",
        "      average = sum(values) / len(values)\n",
        "      return  '{:.2f}'.format(average)\n",
        "    return 0\n",
        "\n",
        "# Function to extract information from a Wikipedia link\n",
        "def extract_wikipedia_info(link):\n",
        "    response = requests.get(link)\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Extract the main content of the page\n",
        "    main_content = soup.find(id='mw-content-text')\n",
        "    if main_content is None:\n",
        "        return None\n",
        "\n",
        "    # Extract the document length\n",
        "    document_length = get_document_length(main_content.get_text())\n",
        "\n",
        "    # Extract the length of data under each headline\n",
        "    headlines = main_content.find_all('span', {'class': 'mw-headline'})\n",
        "    headlines_length = []\n",
        "    for headline in headlines:\n",
        "        next_p = headline.find_next('p')\n",
        "        if next_p is not None:\n",
        "            headlines_length.append(get_document_length(next_p.get_text()))\n",
        "\n",
        "    # Extract the number of links per document\n",
        "    document_links = main_content.find_all('a')\n",
        "    relevant_links = [link for link in document_links if link.get('href') and not link.get('class')]\n",
        "    links_per_document = len(relevant_links)\n",
        "\n",
        "    # Extract the number of links per section\n",
        "    links_per_section = []\n",
        "    sections = main_content.find_all('h2')\n",
        "    for section in sections:\n",
        "        section_links = section.find_next_sibling('ul').find_all('a')\n",
        "        relevant_section_links = [link for link in section_links if link.get('href') and not link.get('class')]\n",
        "        links_per_section.append(len(relevant_section_links))\n",
        "\n",
        "    # Extract the number of images for the entire document\n",
        "    images = main_content.find_all('img')\n",
        "    num_images = len(images)\n",
        "\n",
        "    # Extract the number of images per section\n",
        "    images_per_section = []\n",
        "    for section in sections:\n",
        "        section_images = section.find_next_sibling('ul').find_all('img')\n",
        "        images_per_section.append(len(section_images))\n",
        "\n",
        "    # Extract the number of duplicate links\n",
        "    unique_links = set(link.get('href') for link in relevant_links)\n",
        "    num_duplicate_links = len(relevant_links) - len(unique_links)\n",
        "\n",
        "    return {\n",
        "        'Document Length': document_length,\n",
        "        'Average Length of Data per Headline': calculate_average(headlines_length),\n",
        "        'Links per Document': links_per_document,\n",
        "        'Average Links per Section':  calculate_average(links_per_section),\n",
        "        'Number of Images for Entire Document': num_images,\n",
        "        'Average Images per Section': calculate_average(images_per_section),\n",
        "        'Number of Duplicate Links': num_duplicate_links\n",
        "    }\n",
        "\n",
        "# Provide the Wikipedia link for extraction\n",
        "link = 'https://en.wikipedia.org/wiki/Apple_Inc.'\n",
        "\n",
        "# Extract information from the link\n",
        "result = extract_wikipedia_info(link)\n",
        "\n",
        "# Print the results\n",
        "if result is not None:\n",
        "    for key, value in result.items():\n",
        "        print(key + ':', value)\n",
        "else:\n",
        "    print(\"Failed to extract information from the provided link.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phq6Ns4fZicl",
        "outputId": "290ceb35-7d9d-415e-c6af-e7397a0be2a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Length: 36205\n",
            "Average Length of Data per Headline: 100.70\n",
            "Links per Document: 3364\n",
            "Average Links per Section: 6.33\n",
            "Number of Images for Entire Document: 53\n",
            "Average Images per Section: 0.33\n",
            "Number of Duplicate Links: 836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "# Function to extract the length of a document\n",
        "def get_document_length(text):\n",
        "    words = word_tokenize(text)\n",
        "    return len(words)\n",
        "\n",
        "# Function to calculate the average value\n",
        "def calculate_average(values):\n",
        "    if len(values) > 0:\n",
        "        average = sum(values) / len(values)\n",
        "        return '{:.2f}'.format(average)\n",
        "    return 0\n",
        "\n",
        "# Function to extract information from a Wikipedia link\n",
        "def extract_wikipedia_info(link):\n",
        "    response = requests.get(link)\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Extract the main content of the page\n",
        "    main_content = soup.find(id='mw-content-text')\n",
        "    if main_content is None:\n",
        "        return None\n",
        "\n",
        "    # Extract the document length\n",
        "    document_length = get_document_length(main_content.get_text())\n",
        "\n",
        "    # Extract the length of data under each headline\n",
        "    headlines = main_content.find_all('span', {'class': 'mw-headline'})\n",
        "    headlines_length = []\n",
        "    for headline in headlines:\n",
        "        next_p = headline.find_next('p')\n",
        "        if next_p is not None:\n",
        "            headlines_length.append(get_document_length(next_p.get_text()))\n",
        "\n",
        "    # Extract the number of links per document\n",
        "    document_links = main_content.find_all('a')\n",
        "    relevant_links = [link for link in document_links if link.get('href') and not link.get('class')]\n",
        "    links_per_document = len(relevant_links)\n",
        "\n",
        "    # Extract the number of links per section\n",
        "    links_per_section = []\n",
        "    sections = main_content.find_all('h2')\n",
        "    for section in sections:\n",
        "        section_links = section.find_next_sibling('ul').find_all('a')\n",
        "        relevant_section_links = [link for link in section_links if link.get('href') and not link.get('class')]\n",
        "        links_per_section.append(len(relevant_section_links))\n",
        "\n",
        "    # Extract the number of images for the entire document\n",
        "    images = main_content.find_all('img')\n",
        "    num_images = len(images)\n",
        "\n",
        "    # Extract the number of images per section\n",
        "    images_per_section = []\n",
        "    for section in sections:\n",
        "        section_images = section.find_next_sibling('ul').find_all('img')\n",
        "        images_per_section.append(len(section_images))\n",
        "\n",
        "    # Extract the number of duplicate links\n",
        "    unique_links = set(link.get('href') for link in relevant_links)\n",
        "    num_duplicate_links = len(relevant_links) - len(unique_links)\n",
        "\n",
        "    return {\n",
        "        'Link': link,\n",
        "        'Document Length': document_length,\n",
        "        'Average Length of Data per Headline': calculate_average(headlines_length),\n",
        "        'Links per Document': links_per_document,\n",
        "        'Average Links per Section': calculate_average(links_per_section),\n",
        "        'Number of Images for Entire Document': num_images,\n",
        "        'Average Images per Section': calculate_average(images_per_section),\n",
        "        'Number of Duplicate Links': num_duplicate_links\n",
        "    }\n",
        "\n",
        "# Provide a list of Wikipedia links for extraction\n",
        "links = [\n",
        "    'https://en.wikipedia.org/wiki/Apple_Inc.',\n",
        "    'https://en.wikipedia.org/wiki/Microsoft',\n",
        "    'https://en.wikipedia.org/wiki/Google',\n",
        "    'https://en.wikipedia.org/wiki/Facebook',\n",
        "    'https://en.wikipedia.org/wiki/Amazon_(company)',\n",
        "    'https://en.wikipedia.org/wiki/Netflix',\n",
        "    'https://en.wikipedia.org/wiki/IBM',\n",
        "    'https://en.wikipedia.org/wiki/Tesla,_Inc.',\n",
        "    'https://en.wikipedia.org/wiki/SpaceX',\n",
        "    'https://en.wikipedia.org/wiki/OpenAI'\n",
        "]\n",
        "\n",
        "# Create an empty list to store the results\n",
        "results = []\n",
        "\n",
        "# Iterate over the links and extract information\n",
        "for link in links:\n",
        "    result = extract_wikipedia_info(link)\n",
        "    if result is not None:\n",
        "        results.append(result)\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "# df = pd.DataFrame(results)\n",
        "\n",
        "# Display the table\n",
        "# print(df)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sthxyyU9saUw",
        "outputId": "7d76726e-cd65-442b-b7d9-c4b358b90eb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Link': 'https://en.wikipedia.org/wiki/Apple_Inc.',\n",
              "  'Document Length': 36205,\n",
              "  'Average Length of Data per Headline': '100.70',\n",
              "  'Links per Document': 3364,\n",
              "  'Average Links per Section': '6.33',\n",
              "  'Number of Images for Entire Document': 53,\n",
              "  'Average Images per Section': '0.33',\n",
              "  'Number of Duplicate Links': 836},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/Microsoft',\n",
              "  'Document Length': 23385,\n",
              "  'Average Length of Data per Headline': '163.43',\n",
              "  'Links per Document': 1860,\n",
              "  'Average Links per Section': '3.33',\n",
              "  'Number of Images for Entire Document': 40,\n",
              "  'Average Images per Section': '2.83',\n",
              "  'Number of Duplicate Links': 351},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/Google',\n",
              "  'Document Length': 28909,\n",
              "  'Average Length of Data per Headline': '98.07',\n",
              "  'Links per Document': 2916,\n",
              "  'Average Links per Section': '2.33',\n",
              "  'Number of Images for Entire Document': 116,\n",
              "  'Average Images per Section': '0.11',\n",
              "  'Number of Duplicate Links': 578},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/Facebook',\n",
              "  'Document Length': 44444,\n",
              "  'Average Length of Data per Headline': '85.58',\n",
              "  'Links per Document': 2677,\n",
              "  'Average Links per Section': '5.11',\n",
              "  'Number of Images for Entire Document': 33,\n",
              "  'Average Images per Section': '0.33',\n",
              "  'Number of Duplicate Links': 376},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/Amazon_(company)',\n",
              "  'Document Length': 15014,\n",
              "  'Average Length of Data per Headline': '92.63',\n",
              "  'Links per Document': 1721,\n",
              "  'Average Links per Section': '18.11',\n",
              "  'Number of Images for Entire Document': 35,\n",
              "  'Average Images per Section': '0.78',\n",
              "  'Number of Duplicate Links': 250},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/Netflix',\n",
              "  'Document Length': 31293,\n",
              "  'Average Length of Data per Headline': '111.63',\n",
              "  'Links per Document': 2717,\n",
              "  'Average Links per Section': '3.10',\n",
              "  'Number of Images for Entire Document': 54,\n",
              "  'Average Images per Section': '3.10',\n",
              "  'Number of Duplicate Links': 379},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/IBM',\n",
              "  'Document Length': 16836,\n",
              "  'Average Length of Data per Headline': '129.90',\n",
              "  'Links per Document': 1289,\n",
              "  'Average Links per Section': '1.27',\n",
              "  'Number of Images for Entire Document': 44,\n",
              "  'Average Images per Section': '1.00',\n",
              "  'Number of Duplicate Links': 194},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/Tesla,_Inc.',\n",
              "  'Document Length': 43286,\n",
              "  'Average Length of Data per Headline': '99.70',\n",
              "  'Links per Document': 3008,\n",
              "  'Average Links per Section': '4.95',\n",
              "  'Number of Images for Entire Document': 51,\n",
              "  'Average Images per Section': '0.05',\n",
              "  'Number of Duplicate Links': 492},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/SpaceX',\n",
              "  'Document Length': 22636,\n",
              "  'Average Length of Data per Headline': '95.55',\n",
              "  'Links per Document': 1528,\n",
              "  'Average Links per Section': '3.67',\n",
              "  'Number of Images for Entire Document': 56,\n",
              "  'Average Images per Section': '0.11',\n",
              "  'Number of Duplicate Links': 353},\n",
              " {'Link': 'https://en.wikipedia.org/wiki/OpenAI',\n",
              "  'Document Length': 12590,\n",
              "  'Average Length of Data per Headline': '78.73',\n",
              "  'Links per Document': 837,\n",
              "  'Average Links per Section': '5.22',\n",
              "  'Number of Images for Entire Document': 20,\n",
              "  'Average Images per Section': '0.33',\n",
              "  'Number of Duplicate Links': 132}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "    print(\"Link:\", result['Link'])\n",
        "    print(\"Document Length:\", result['Document Length'])\n",
        "    print(\"Average Length of Data per Headline:\", result['Average Length of Data per Headline'])\n",
        "    print(\"Links per Document:\", result['Links per Document'])\n",
        "    print(\"Average Links per Section:\", result['Average Links per Section'])\n",
        "    print(\"Number of Images for Entire Document:\", result['Number of Images for Entire Document'])\n",
        "    print(\"Average Images per Section:\", result['Average Images per Section'])\n",
        "    print(\"Number of Duplicate Links:\", result['Number of Duplicate Links'])\n",
        "    print()#for empty line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEG0WeDQcyw6",
        "outputId": "94d3dee2-b97b-4cd9-c254-5299a1578400"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Link: https://en.wikipedia.org/wiki/Apple_Inc.\n",
            "Document Length: 36205\n",
            "Average Length of Data per Headline: 100.70\n",
            "Links per Document: 3364\n",
            "Average Links per Section: 6.33\n",
            "Number of Images for Entire Document: 53\n",
            "Average Images per Section: 0.33\n",
            "Number of Duplicate Links: 836\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/Microsoft\n",
            "Document Length: 23385\n",
            "Average Length of Data per Headline: 163.43\n",
            "Links per Document: 1860\n",
            "Average Links per Section: 3.33\n",
            "Number of Images for Entire Document: 40\n",
            "Average Images per Section: 2.83\n",
            "Number of Duplicate Links: 351\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/Google\n",
            "Document Length: 28909\n",
            "Average Length of Data per Headline: 98.07\n",
            "Links per Document: 2916\n",
            "Average Links per Section: 2.33\n",
            "Number of Images for Entire Document: 116\n",
            "Average Images per Section: 0.11\n",
            "Number of Duplicate Links: 578\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/Facebook\n",
            "Document Length: 44444\n",
            "Average Length of Data per Headline: 85.58\n",
            "Links per Document: 2677\n",
            "Average Links per Section: 5.11\n",
            "Number of Images for Entire Document: 33\n",
            "Average Images per Section: 0.33\n",
            "Number of Duplicate Links: 376\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/Amazon_(company)\n",
            "Document Length: 15014\n",
            "Average Length of Data per Headline: 92.63\n",
            "Links per Document: 1721\n",
            "Average Links per Section: 18.11\n",
            "Number of Images for Entire Document: 35\n",
            "Average Images per Section: 0.78\n",
            "Number of Duplicate Links: 250\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/Netflix\n",
            "Document Length: 31293\n",
            "Average Length of Data per Headline: 111.63\n",
            "Links per Document: 2717\n",
            "Average Links per Section: 3.10\n",
            "Number of Images for Entire Document: 54\n",
            "Average Images per Section: 3.10\n",
            "Number of Duplicate Links: 379\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/IBM\n",
            "Document Length: 16836\n",
            "Average Length of Data per Headline: 129.90\n",
            "Links per Document: 1289\n",
            "Average Links per Section: 1.27\n",
            "Number of Images for Entire Document: 44\n",
            "Average Images per Section: 1.00\n",
            "Number of Duplicate Links: 194\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/Tesla,_Inc.\n",
            "Document Length: 43286\n",
            "Average Length of Data per Headline: 99.70\n",
            "Links per Document: 3008\n",
            "Average Links per Section: 4.95\n",
            "Number of Images for Entire Document: 51\n",
            "Average Images per Section: 0.05\n",
            "Number of Duplicate Links: 492\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/SpaceX\n",
            "Document Length: 22636\n",
            "Average Length of Data per Headline: 95.55\n",
            "Links per Document: 1528\n",
            "Average Links per Section: 3.67\n",
            "Number of Images for Entire Document: 56\n",
            "Average Images per Section: 0.11\n",
            "Number of Duplicate Links: 353\n",
            "\n",
            "Link: https://en.wikipedia.org/wiki/OpenAI\n",
            "Document Length: 12590\n",
            "Average Length of Data per Headline: 78.73\n",
            "Links per Document: 837\n",
            "Average Links per Section: 5.22\n",
            "Number of Images for Entire Document: 20\n",
            "Average Images per Section: 0.33\n",
            "Number of Duplicate Links: 132\n",
            "\n"
          ]
        }
      ]
    }
  ]
}